\subsection{Examining Convergence Using Multiple Grids}
When repeating the simulation while increasing the number of grid points is standard 
practice when conducting a numerical approximation. The discretization errors that
initially arise should asymptotically approach zero, excluding computer round-off error. 

Although it is desirable to know the error band for the results obtained from a 
fine grid, the study may require a coarse grid due to time constraints for design
iteration. Furthermore, as the grid gets finer, the computational time required 
increases. So it is desirable to compute the discretization on grids with fewer points
to get a sense of where the asymptotic range is located. The approach for generating
the series of grids is to generate a grid with what the user would consider small or
fine grid spacing, reaching the upper limit of one's tolerance for generating a grid. Otherwise, the finest grid that requires the least amount of computation on that grid to converge should be chosen. Then coarser grids can be obtained by removing every other grid point. Finally, the
number of iterations can be increased to create additional levels of coarse grids.
For example, in generating the fine grid, one can choose the number of coarser grids
by satisfying the following relation,

\begin{equation}
    N = (2^n)m + 1
\end{equation}
where, $N$ is the number of grid points, $n$ is the iteration level, and $m$ is 
an arbitrary integer. The base $2$ has the effect of doubling grid points. However
$m$ can change between iterations which will allow for grids which are fractions of double.

One can use the finest grid that was run to determine how to iterate from a coarser
grid up to a finer one. Note that the number of grid points does not to be doubled
each time, however the grid refnement should be such that the ratio between grid spacing 
it is less than $0.91$ since it is easier to determine which errors occur from
discretization as opposed to computer round-off error or iterative convergence 
errors.  

For this work, the number of grid points will be computed using the following 
\subsection{Calculation of Observed Order-of-Accuracy}
The numerical scheme used to perform the integration of the tangential velocity
will have a theoretical order-of-accuracy. To find the theoretical 
order-of-accuracy, the discretization error must first be defined. The error, 
$\epsilon$, is a function of grid spacing, $\Delta r$

\[ \epsilon = \epsilon(\Delta r) \]

The discretization error in the solution should be proportional to 
$\left( \Delta r \right)^{\alpha}$ where $\alpha > 0$ is the theoretical order
for the computational method.  An error between two quantities can expressed as 
\[ \epsilon(\Delta r) = |f_{analytic}-f_{calc}|\]
where $f_{analytic}$ is the function value of an analytic solution and $f_{calc}$ 
represents some calculated value.  The $\Delta r$ is to indicate that this is a discretization error for a
specific grid spacing. 

If we define this error on various grid sizes and compute $\epsilon$ for
each grid, the observed order of accuracy can be estimated and compared to
the theoretical order of accuracy. For instance, if the numerical soution
is second-order accurate and the error is converging to a value, the $L_2$ norm of
the error will decrease by a factor of 4 for every halving of the grid cell 
size. 

For a perfect answer, we expect $\epsilon$ to be zero. Since a Taylor series can 
be used to derive the numerical schemes, we know that the truncation of higher
order terms is what indicates the error we expect from using a scheme that 
is constructed with such truncated Taylor series.

The error at each grid point $j$ is expected to satisfy the following,

\begin{align*}
    0 &= |f_{analytic}(r_j) - f_{calc}(r_j)| \\
    f_{analytic}(r_j) &= {f}_{calc}(r_j) +
    (\Delta r)^{\alpha} \beta(r_j)  + H.O.T
\end{align*}

where the value of $\beta(r_j)$ does not change with grid spacing, and 
$\alpha$ is the asymptotic order of accuracy of the method. It is important to
note that the numerical method recovers the original equations as the grid 
spacing approached zero.  It is important to note that $\beta$ represents the
first derivative of the Taylor Series.  Subtracting $f_{analytic}$ from both
sides gives,

\begin{align*}
    f_{calc}(r_j) - f_{analytic}(r_j) &= f_{analytic}(r_j) - f_{analytic}(r_j)
    + \beta(r_j) (\Delta r)^{\alpha} \\
    \epsilon_(r_j)(\Delta r) &= \beta(r_j) (\Delta r)^{\alpha}
\end{align*}

To estimate the order of accuracy of the accuracy, we define the global errors 
by calculating the L2 Norm of the error which is denoted as $\hat{\epsilon}$ 

\begin{align*}
    \hat{\epsilon} = \sqrt{\frac{1}{N}\sum_{j=1}^{N} \epsilon(r_j)^2  }
\end{align*}

\begin{align*}
    \hat{\beta}(r_j) = \sqrt{\frac{1}{N}\sum_{j=1}^{N} \beta(r_j)^2  }
\end{align*}

As the grid density increases, $\hat{\beta}$ should asymptote to a constant 
value. Given two grid densities, $\Delta r$ and $\sigma\Delta r$, and assuming
that the leading error term is much larger than any other error term,

\begin{align*}
    \hat{\epsilon}_{grid 1} &= \hat{\epsilon}(\Delta r) = \hat{\beta}(\Delta r)^{\alpha} \\
    \hat{\epsilon}_{grid 2} &= \hat{\epsilon}(\sigma \Delta r) = \hat{\beta}(\sigma \Delta r)^{\alpha} \\
                            &= \hat{\beta}(\Delta r)^{\alpha} \sigma^{\alpha}
\end{align*}

The ratio of two errors is given by,

\begin{align*}
    \frac{\hat{\epsilon}_{grid 2}}{\hat{\epsilon}_{grid 1}} &= 
    \frac{\hat{\beta}(\Delta r )^{\alpha}}{\hat{\beta}(\Delta r )^{\alpha}} \sigma^{\alpha} \\ &= \sigma^{\alpha}
\end{align*}

Thus, $\alpha$,the asymptotic rate of convergence is computed as follows 

\begin{align*}
    \alpha = \frac{
        \ln \frac{
            \hat{\epsilon}_{grid 2}
    }{\hat{\epsilon}_{grid 1} }}
    {\ln\left( \sigma \right) }
\end{align*}

Defining  for a doubling of grid points ,

\begin{align*}
    \alpha = \frac{\ln \left( \hat{\epsilon}\left( \frac{1}{2}\Delta  r\right)
            \right) -\ln \left( \hat{\epsilon}\left( \Delta  r\right)
    \right)}{\ln \left( \frac{1}{2} \right)}
\end{align*}

%Similarly for the eigenvalue problem, 
%Initially the source terms were defined without mention of the indicies of the 
%matricies they make up. In other words, there was no fore sight on the fact 
%that these source terms are sums of the elements within A,B, and X. 
%To investigate the source terms in greater detail, the FORTRAN code 
%that calls the source terms will output the terms within the source term 
%and then sum them, instead of just their sum.
%
%\[ [A]x - \lambda [B]x = 0 \]
%
%
%
